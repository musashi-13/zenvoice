services:
  kafka:
    image: bitnami/kafka:latest
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@127.0.0.1:9093
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka_data:/bitnami/kafka
    healthcheck:
      test: ["CMD", "/opt/bitnami/kafka/bin/kafka-topics.sh", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - kafka-network

  init-kafka:
    image: bitnami/kafka:latest
    container_name: init-kafka
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      echo -e 'Creating Kafka topics'
      /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic email-invoices --replication-factor 1 --partitions 3
      /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic logs --replication-factor 1 --partitions 3
      echo -e 'Successfully created topics:'
      /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list
      "
    networks:
      - kafka-network

  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=invoice-pipeline
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d invoice-pipeline"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kafka-network

  email-monitor:
    build:
      context: ./email_monitor
      dockerfile: Dockerfile
    container_name: email-monitor
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      # Mount the new logger and updated Zoho files
      - ./email_monitor/logger_config.py:/app/logger_config.py
      - ./email_monitor/zoho_api.py:/app/zoho_api.py
      - ./email_monitor/zoho_auth.py:/app/zoho_auth.py
      # IMPORTANT: Use zoho_tokens.json now, not .pickle
      - ./email_monitor/zoho_tokens.json:/app/zoho_tokens.json
    ports:
      - "8080:8080"
    environment:
      # --- Logging Configuration ---
      - LOG=${LOG}
      - SERVICE_NAME_LOG_VAR=EMAIL_MONITOR_LOG
      - EMAIL_MONITOR_LOG=${EMAIL_MONITOR_LOG}
      # --- Original Environment Vars ---
      - PYTHONUNBUFFERED=1
      - OAUTH_PORT=8080
      - AWS_ACCESS_KEY=${AWS_ACCESS_KEY}
      - AWS_SECRET_KEY=${AWS_SECRET_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - ZOHO_CLIENT_ID=${ZOHO_CLIENT_ID}
      - ZOHO_CLIENT_SECRET=${ZOHO_CLIENT_SECRET}
      - ZOHO_AUTH_CODE=${ZOHO_AUTH_CODE}
      - ZOHO_REDIRECT_URI=${ZOHO_REDIRECT_URI}
      - ZOHO_ORGANIZATION_ID=${ZOHO_ORGANIZATION_ID}
    networks:
      - kafka-network

  invoice-uploader:
    build:
      context: ./invoice_uploader
      dockerfile: Dockerfile
    container_name: invoice-uploader
    depends_on:
      - kafka
      - postgres
    volumes:
      # Mount the logger config into this service
      - ./invoice_uploader/logger_config.py:/app/logger_config.py
    environment:
      # --- Logging Configuration ---
      - LOG=${LOG}
      - SERVICE_NAME_LOG_VAR=INVOICE_UPLOADER_LOG
      - INVOICE_UPLOADER_LOG=${INVOICE_UPLOADER_LOG}
      # --- Original Environment Vars ---
      - PYTHONUNBUFFERED=1
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=invoice-pipeline
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - AWS_ACCESS_KEY=${AWS_ACCESS_KEY}
      - AWS_SECRET_KEY=${AWS_SECRET_KEY}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
    networks:
      - kafka-network

  invoice-processor:
    build:
      context: ./invoice_processor
      dockerfile: Dockerfile
    container_name: invoice-processor
    depends_on:
      - kafka
      - postgres
    volumes:
      # Mount the new logger and updated Zoho files
      - ./invoice_processor/logger_config.py:/app/logger_config.py
      - ./invoice_processor/zoho_api.py:/app/zoho_api.py
      - ./invoice_processor/zoho_auth.py:/app/zoho_auth.py
      # IMPORTANT: Use zoho_tokens.json now, not .pickle
      - ./invoice_processor/zoho_tokens.json:/app/zoho_tokens.json
    environment:
      # --- Logging Configuration ---
      - LOG=${LOG}
      - SERVICE_NAME_LOG_VAR=INVOICE_PROCESSOR_LOG
      - INVOICE_PROCESSOR_LOG=${INVOICE_PROCESSOR_LOG}
      # --- Original Environment Vars ---
      - PYTHONUNBUFFERED=1
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=invoice-pipeline
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - ZOHO_CLIENT_ID=${ZOHO_CLIENT_ID}
      - ZOHO_CLIENT_SECRET=${ZOHO_CLIENT_SECRET}
      - ZOHO_AUTH_CODE=${ZOHO_AUTH_CODE}
      - ZOHO_REDIRECT_URI=${ZOHO_REDIRECT_URI}
      - ZOHO_ORGANIZATION_ID=${ZOHO_ORGANIZATION_ID}
    networks:
      - kafka-network

  express-backend:
    build:
      context: ./express-backend
      dockerfile: Dockerfile
    container_name: express-backend
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "4000:4000"
    environment:
      # Add the logging variable for Express if you implement it there
      - EXPRESS_BACKEND_LOG=${EXPRESS_BACKEND_LOG}
      - DATABASE_URL=postgresql://user:password@postgres:5432/invoice-pipeline?schema=public
      - PORT=4000
      - AWS_ACCESS_KEY=${AWS_ACCESS_KEY}
      - AWS_SECRET_KEY=${AWS_SECRET_KEY}
      - ZOHO_CLIENT_ID=${ZOHO_CLIENT_ID}
      - ZOHO_CLIENT_SECRET=${ZOHO_CLIENT_SECRET}
      - ZOHO_ORGANIZATION_ID=${ZOHO_ORGANIZATION_ID}
    volumes:
      - ./express-backend/src/public:/app/public
      - ./express-backend/zoho_tokens.json:/app/zoho_tokens.json
    networks:
      - kafka-network

volumes:
  kafka_data:
    driver: local
  postgres_data:
    driver: local

networks:
  kafka-network:
    driver: bridge
